{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains\n",
    "\n",
    "Hello everyone! Here, we will explore the work behind chaining\n",
    "\n",
    "Concepts covered in this notebook are:\n",
    "1. [Basic Chaining](#1)\n",
    "2. [Level 1 - Chaining is Passing](#2)\n",
    "3. [Level 2 - Chaining is Runnable Sequence](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "## By default, load_dotenv() will assign environment variables into os.environ, like following code:\n",
    "## See environment variables in .env file\n",
    "# import os\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] =  os.getenv('LANGCHAIN_API_KEY')\n",
    "# os.environ[\"OPENAPI_KEY\"] =  os.getenv('OPENAI_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create language model instance, prompt template, and output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"Translete the following into {language}\"),\n",
    "    (\"user\", \"{text}\")\n",
    "])\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Chaining\n",
    "\n",
    "\"Chaining\" is operation to combine sequential processes — for example from prompt templates to output parsers— using the pipe (`|`) operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apa kabar?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_template | model | parser\n",
    "\n",
    "chain.invoke({\"language\": \"indonesia\", \"text\": \"How are you?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Chaining Under the Hood <div id=\"2\"></div>\n",
    "\n",
    "Chaining is an incredible operation in LangChain. While understanding it as a combination of sequential processes is a good start, mastering chaining requires a deeper understanding of how it works internally. I will explain this with three levels of abstraction.\n",
    "\n",
    "### 2.1 -  Chaining is Passing Output From Previous to Next Component \n",
    "\n",
    "Here’s a breakdown of what happens during chaining:\n",
    "\n",
    "<img src=\"../../images/1.png\" width=\"600px\"/>\n",
    "\n",
    "- Invoke the Chain: Pass initial arguments (e.g., language and text) to the chain object.\n",
    "\n",
    "- Pass to `prompt_template`: Convert the arguments into messages using the prompt_template.\n",
    "\n",
    "- Pass to `model`: Generate a response from the model based on the formatted messages.\n",
    "\n",
    "- Pass to `parser`: Convert the model's response into the final output format using the parser.\n",
    "\n",
    "This sequential flow allows each component to process and transform data effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Chaining is Creating `RunnableSequence` containing `Runnable`s\n",
    "\n",
    "Chain operation (`|`) in langchain is part of LangChain Expression Language (LCEL). \n",
    "\n",
    "When we create a chain, we are essentially creating an object called `RunnableSequence`. Each component in this sequence must implement the `Runnable` interface.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "chain = prompt_template | model | parser\n",
    "```\n",
    "\n",
    "In this code:\n",
    "- `chain` is an instance of `RunnableSequence`.\n",
    "- `prompt_template`, `model`, and `parser` are instances of components that implement the `Runnable` interface.\n",
    "\n",
    "### `Runnable` Interface\n",
    "\n",
    "Many LangChain components, including chat models, LLMs, output parsers, retrievers, and prompt templates, implement the `Runnable` interface. This interface includes two most important methods:\n",
    "\n",
    "- **`invoke`**: Calls the chain on a single input.\n",
    "- **`__or__`**: This is operator overloading, that enable Runnable to overwrite `|` (pipe) operator and turn it into forming RunnableSequence. This looks like:\n",
    "\n",
    "```python\n",
    "class Runnable:\n",
    "    def __or__(self, other):\n",
    "        # Handle chaining with the pipe operator\n",
    "        return RunnableSequence(first=self, middle=[other], last=None)\n",
    "```\n",
    "\n",
    "For example:\n",
    "```python\n",
    "chain = component1 | component2\n",
    "\n",
    "# is equivalent to\n",
    "chain = component1.__or__(component2)\n",
    "\n",
    "# Equivalent to\n",
    "chain = RunnableSequence(first=component1, last=component2)\n",
    "```\n",
    "\n",
    "### `RunnableSequence` instances\n",
    "\n",
    "RunnableSequence is a special type of `Runnable` that allows chaining multiple `Runnable`s together. It has three important attributes:\n",
    "\n",
    "- `first`: The first `Runnable` in the sequence.\n",
    "- `middle`: A list of `Runnable`s that follow the `first` `Runnable`.\n",
    "- `last`: The last `Runnable` in the sequence.\n",
    "\n",
    "RunnableSequence also has two most important methods:\n",
    "\n",
    "- **`invoke`**: Calls the chain on a single input.\n",
    "- **`__or__`**: override pipe (`|`) operator\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "chain = component1 | component2 | component3\n",
    "\n",
    "# Equivalent to\n",
    "\n",
    "chain = component1.__or__(component2).__or__(component3)\n",
    "\n",
    "# Equivalent to\n",
    "\n",
    "chain = RunnableSequence(first=component1, last=component2).__or__(component3)\n",
    "\n",
    "# Equivalent to\n",
    "\n",
    "chain = RunnableSequence(first=component1, middle=[component2], last=component3)\n",
    "\n",
    "```\n",
    "\n",
    "You can learn more about the `Runnable` interface in the [Runnable Interface documentation](https://python.langchain.com/v0.2/docs/concepts/#runnable-interface)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's experiment with Runnable and RunnableSequence**\n",
    "\n",
    "To make a function become `Runnable` we can pass it to `RunnableLambda` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result from chain invocation: 10.0\n",
      "Result from component invocation and passing: 10.0\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableLambda, RunnableSequence\n",
    "\n",
    "# Create a Runnable functions\n",
    "double = RunnableLambda(lambda x: 2*x)\n",
    "square = RunnableLambda(lambda x: x**2)\n",
    "tenth = RunnableLambda(lambda x : x / 10)\n",
    "\n",
    "# Create a Runnable sequence using pipe operator\n",
    "chain = double | square | tenth\n",
    "\n",
    "result1 = chain.invoke(5)\n",
    "\n",
    "print(f\"Result from chain invocation: {result1}\")\n",
    "\n",
    "# Try to invoke sequence one by one and passing it\n",
    "result2 = double.invoke(5)\n",
    "result2 = square.invoke(result2)\n",
    "result2 = tenth.invoke(result2)\n",
    "\n",
    "print(f\"Result from component invocation and passing: {result2}\")\n",
    "\n",
    "# ((2*5)^2)/10 = 100/10 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "10.0\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "chain = double | square | tenth\n",
    "\n",
    "result1 = chain.invoke(5)\n",
    "\n",
    "# equivalent to\n",
    "\n",
    "chain = double.__or__(square).__or__(tenth)\n",
    "\n",
    "result2 = chain.invoke(5)\n",
    "\n",
    "# equivalent to\n",
    "\n",
    "chain = RunnableSequence(first=double, middle=[square], last=tenth)\n",
    "\n",
    "result3 = chain.invoke(5)\n",
    "\n",
    "print(result1)\n",
    "print(result2)\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Why did the bee get married? Because he found his honey!\n",
      "\n",
      "2. What do you call a bear with no teeth? A gummy bear!\n",
      "\n",
      "3. Why did the chicken join a band? Because it had the drumsticks!\n"
     ]
    }
   ],
   "source": [
    "# Define prompt templates\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a comedian who tells jokes about {topic}.\"),\n",
    "        (\"human\", \"Tell me {joke_count} jokes.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create individual runnables (steps in the chain)\n",
    "format_prompt = RunnableLambda(lambda x: prompt_template.format_prompt(**x))\n",
    "invoke_model = RunnableLambda(lambda x: model.invoke(x))\n",
    "parse_output = RunnableLambda(lambda x: x.content)\n",
    "\n",
    "# Create the RunnableSequence (equivalent to the LCEL chain)\n",
    "chain = RunnableSequence(first=format_prompt, middle=[invoke_model], last=parse_output)\n",
    "\n",
    "# Run the chain\n",
    "response = chain.invoke({\"topic\": \"animals\", \"joke_count\": 3})\n",
    "\n",
    "# Output\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
