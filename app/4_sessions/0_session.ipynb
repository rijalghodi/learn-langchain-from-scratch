{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session\n",
    "\n",
    "Hello everyone! Here we will explore session in langchain. Session is a concept that allows you to maintain state across multiple interactions with a language model. Things we'll cover are:\n",
    "\n",
    "1. Basic Session using conversation messages\n",
    "2. Using `InMemoryChatHistory`\n",
    "3. Use external database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Session by maintaining conversation messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "sessions = {}  # Use a list to store messages\n",
    "\n",
    "system_message = SystemMessage(content=\"You are a helpful AI assistant.\")\n",
    "\n",
    "def get_session(session_id: int):\n",
    "    if  session_id not in sessions:  \n",
    "        sessions[session_id] = [system_message]\n",
    "    return sessions[session_id]\n",
    "\n",
    "def ask_for_session(session_id, question):\n",
    "    session = get_session(session_id)\n",
    "    session.append(HumanMessage(content=question)) \n",
    "    response = model.invoke(session)\n",
    "    session.append(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Session 0 -----------------\n",
      "Hello, John! How can I assist you today?\n",
      "Your name is John.\n",
      "\n",
      "Session 1 -----------------\n",
      "I'm sorry, I don't have access to personal information about you. How can I assist you today?\n",
      "\n",
      "Summary -------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: [SystemMessage(content='You are a helpful AI assistant.'),\n",
       "  HumanMessage(content='My name is John'),\n",
       "  AIMessage(content='Hello, John! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 22, 'total_tokens': 33}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2ada7949-65b0-47fd-8ece-d7abe645a0f6-0', usage_metadata={'input_tokens': 22, 'output_tokens': 11, 'total_tokens': 33}),\n",
       "  HumanMessage(content='Who is my name?'),\n",
       "  AIMessage(content='Your name is John.', response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 46, 'total_tokens': 51}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c8f7acc5-4f1a-4457-9651-b93d35786b06-0', usage_metadata={'input_tokens': 46, 'output_tokens': 5, 'total_tokens': 51})],\n",
       " 1: [SystemMessage(content='You are a helpful AI assistant.'),\n",
       "  HumanMessage(content='Who is my name?'),\n",
       "  AIMessage(content=\"I'm sorry, I don't have access to personal information about you. How can I assist you today?\", response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 23, 'total_tokens': 45}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4eda4e9c-0451-47b3-9c69-fcdcb4d1c84e-0', usage_metadata={'input_tokens': 23, 'output_tokens': 22, 'total_tokens': 45})]}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nSession 0 -----------------\")\n",
    "response = ask_for_session(0, \"My name is John\") \n",
    "print(response.content)\n",
    "response = ask_for_session(0, \"Who is my name?\")\n",
    "print(response.content)\n",
    "\n",
    "print(\"\\nSession 1 -----------------\")\n",
    "response = ask_for_session(1, \"Who is my name?\") # different session\n",
    "print(response.content)\n",
    "\n",
    "print(\"\\nSummary -------------------\")\n",
    "sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Session using `InMemoryChatMessageHistory`\n",
    "\n",
    "\n",
    "We can create session using langchain class `InMemoryChatMessageHistory`. This will automatically append the human and assistant messages to the currect conversation.\n",
    "\n",
    "To begin, let's create a chain, consists of prompt and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt =  ChatPromptTemplate.from_messages([\n",
    "    ('system', \"You are a helpful assistant. Reply messages with Indonesian language\"),\n",
    "    ('user', '{messages}')\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "chain = prompt | model| StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create `get_session` function that retrivet session from store. Note that now the session is `InMemoryChatMessageHistory` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import (\n",
    "    BaseChatMessageHistory,\n",
    "    InMemoryChatMessageHistory,\n",
    ")\n",
    "\n",
    "# Session\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and lastly, let's wrap our `chain` and `get_session_history` in class `RunnableWithMessageHistory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "\n",
    "app = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can invoke the app with by feeding messages and config that specify session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError()\n",
      "Error in callback coroutine: ValueError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Hi! I'm Bob. Who are you?\"),\n",
       " AIMessage(content='Halo Bob! Saya adalah asisten virtual yang siap membantu Anda. Ada yang bisa saya bantu?')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = app.invoke(\n",
    "    {\"messages\": HumanMessage(content=\"Hi! I'm Bob. Who are you?\")},\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "store['1'].messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind the scene, app invocation will cause:\n",
    "\n",
    "1. `RunnableWithMessageHistory` searches for a session using the `get_session` function.\n",
    "2. If the session is empty, it appends the session with the full prompt. If there is already a session, it will be appended only with the message (human) somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError()\n",
      "Error in callback coroutine: ValueError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Hi! I'm Bob. Who are you?\"),\n",
       " AIMessage(content='Halo Bob! Saya adalah asisten virtual yang siap membantu Anda. Ada yang bisa saya bantu?'),\n",
       " HumanMessage(content=\"What's my name?\"),\n",
       " AIMessage(content='Halo Bob! Saya adalah asisten virtual yang siap membantu Anda. Nama Anda adalah Bob, ada yang bisa saya bantu?')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = app.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response\n",
    "store['1'].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError()\n",
      "Error in callback coroutine: ValueError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"What's my name?\"),\n",
       " AIMessage(content='Maaf, saya tidak punya akses ke informasi pribadi seperti nama Anda. Ada yang bisa saya bantu?')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"2\"}}\n",
    "\n",
    "response = app.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response\n",
    "store['2'].messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session `InMemoryChatMessageHistory` with Two Arguments\n",
    "\n",
    "OK. Now what if we want to pass two arguments to the prompt? It is okey, as long as you define which one is messages_key because it will be appended to the session!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prompt that has two arguments\n",
    "prompt =  ChatPromptTemplate.from_messages([\n",
    "    ('system', \"You are a helpful assistant. Reply messages in {language}\"),\n",
    "    ('user', '{messages}')\n",
    "])\n",
    "\n",
    "chain = prompt | model| StrOutputParser()\n",
    "\n",
    "app = RunnableWithMessageHistory(chain, get_session_history, input_messages_key=\"messages\") # specify the messages key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError()\n",
      "Error in callback coroutine: ValueError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Halo! Ada yang bisa saya bantu?'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"4\"}}\n",
    "\n",
    "app.invoke({\n",
    "    \"language\": \"Indonesian\",\n",
    "    \"messages\": \"Hello\"\n",
    "}, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntatic sugar (`{some_key}`) in prompt only works in string. If you want to pass list of messages as an argument, use `MessagesPlaceholder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# create a prompt that has messages as an argument\n",
    "prompt =  ChatPromptTemplate.from_messages([\n",
    "    ('system', \"You are a helpful assistant. Reply messages in {language}\"),\n",
    "    MessagesPlaceholder(\"message_list\") # message list will be spred here\n",
    "])\n",
    "\n",
    "chain = prompt | model| StrOutputParser()\n",
    "\n",
    "app = RunnableWithMessageHistory(chain, get_session_history, input_messages_key=\"message_list\") # specigy the messages_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError()\n",
      "Error in callback coroutine: ValueError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('human', 'My name is Sukses'),\n",
       " ('system', 'Give them a praise on his name'),\n",
       " AIMessage(content='Halo Sukses! Nama Anda memiliki makna yang sangat positif dan inspiratif. Semoga Anda selalu meraih kesuksesan dalam segala hal yang Anda lakukan. Apakah ada yang bisa saya bantu hari ini?')]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"10\"}}\n",
    "\n",
    "app.invoke({\n",
    "    \"language\": \"Indonesian\",\n",
    "    \"message_list\": [(\"human\", \"My name is Sukses\"), (\"system\", \"Give them a praise on his name\")]\n",
    "}, config=config)\n",
    "\n",
    "store[\"10\"].messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
