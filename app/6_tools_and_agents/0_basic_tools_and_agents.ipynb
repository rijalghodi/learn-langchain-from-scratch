{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Tools and Agents\n",
    "\n",
    "By themselves, language models can't take actions - they just output text. A big use case for LangChain is creating agents. Agents are systems that use LLMs as reasoning engines to determine which actions to take and the inputs to pass them. After executing actions, the results can be fed back into the LLM to determine whether more actions are needed, or whether it is okay to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "\n",
    "def get_current_time(*args, **kwargs):\n",
    "    \"\"\"Returns the current time in H:MM AM/PM format.\"\"\"\n",
    "\n",
    "    now = datetime.datetime.now()  # Get current time\n",
    "    return now.strftime(\"%I:%M:%S %p\")  # Format time in H:MM AM/PM format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10:37:21 AM'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "time_tool = StructuredTool.from_function(\n",
    "    name=\"Time\",  # Name of the tool\n",
    "    func=get_current_time,  # Function that the tool will execute\n",
    "    # Description of the tool\n",
    "    description=\"Useful for when you need to know the current time\",\n",
    ")\n",
    "\n",
    "tools = [time_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I am an AI assistant and I do not have the capability to tell time.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "response = model.invoke([('human', 'Hi, what time is it?')])\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: \n",
      "Tool Calls: [{'name': 'Time', 'args': {'config': {}}, 'id': 'call_BZa8EQC963ienVmMVduFjgEY', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([('human', 'Hi, what time is it?')])\n",
    "\n",
    "print(f\"Content: {response.content}\")\n",
    "print(f\"Tool Calls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there's now no text content, but there is a tool call! It wants us to call the Tavily Search tool.\n",
    "\n",
    "This isn't calling that tool yet - it's just telling us to. In order to actually call it, we'll want to create our agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(model, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, what time is it?', id='c1cceb03-f0b5-4c59-93f4-01da33bf19c9'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_zKUQGU3gO3G8GhBhd0vEM6JM', 'function': {'arguments': '{\"config\":{}}', 'name': 'Time'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 99, 'total_tokens': 112}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-59455eec-0c1a-4282-8b97-4f3b652b257b-0', tool_calls=[{'name': 'Time', 'args': {'config': {}}, 'id': 'call_zKUQGU3gO3G8GhBhd0vEM6JM', 'type': 'tool_call'}], usage_metadata={'input_tokens': 99, 'output_tokens': 13, 'total_tokens': 112}),\n",
       " ToolMessage(content='10:47:16 AM', name='Time', id='43806b80-81c3-4c94-9b10-df7b25e8ae9f', tool_call_id='call_zKUQGU3gO3G8GhBhd0vEM6JM'),\n",
       " AIMessage(content='It is currently 10:47:16 AM.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 125, 'total_tokens': 137}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b81fbfd9-83e2-4bff-b3e6-996ccfbdd8b8-0', usage_metadata={'input_tokens': 125, 'output_tokens': 12, 'total_tokens': 137})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"messages\": [('human', 'Hi, what time is it?')]})\n",
    "\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_GS7wsERJwRkibZRsvufTU7Rf', 'function': {'arguments': '{\"config\":{}}', 'name': 'Time'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 99, 'total_tokens': 112}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0e56ea17-888c-4595-bd96-35de258815b4-0', tool_calls=[{'name': 'Time', 'args': {'config': {}}, 'id': 'call_GS7wsERJwRkibZRsvufTU7Rf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 99, 'output_tokens': 13, 'total_tokens': 112})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='10:50:08 AM', name='Time', tool_call_id='call_GS7wsERJwRkibZRsvufTU7Rf')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='I currently do not have the ability to check the weather. Please let me know if you would like me to assist you with anything else.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 125, 'total_tokens': 154}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdc7921-0d5a-4787-a597-1a8db8062c2b-0', usage_metadata={'input_tokens': 125, 'output_tokens': 29, 'total_tokens': 154})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [(\"human\", \"whats the weather in sf?\")]}\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, this agent is stateless. This means it does not remember previous interactions. To give it memory we need to pass in a checkpointer. When passing in a checkpointer, we also have to pass in a thread_id when invoking the agent (so it knows which thread/conversation to resume from).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0682e2b6-cef1-400f-b4a5-dcaca93ac632-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [('human', 'hi')]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
