{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Tools and Agents\n",
    "\n",
    "By themselves, language models can't take actions - they just output text. A big use case for LangChain is creating agents. Agents are systems that use LLMs as reasoning engines to determine which actions to take and the inputs to pass them. After executing actions, the results can be fed back into the LLM to determine whether more actions are needed, or whether it is okay to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "\n",
    "def get_current_time(*args, **kwargs):\n",
    "    \"\"\"Returns the current time in H:MM AM/PM format.\"\"\"\n",
    "\n",
    "    now = datetime.datetime.now()  # Get current time\n",
    "    return now.strftime(\"%I:%M:%S %p\")  # Format time in H:MM AM/PM format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'09:24:33 PM'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "time_tool = StructuredTool.from_function(\n",
    "    name=\"Time\",  # Name of the tool\n",
    "    func=get_current_time,  # Function that the tool will execute\n",
    "    # Description of the tool\n",
    "    description=\"Useful for when you need to know the current time\",\n",
    ")\n",
    "\n",
    "tools = [time_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I am a virtual assistant and I do not have the capability to know the current time. You can check the time on your device or ask a voice assistant like Siri or Google Assistant for the current time.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "response = model.invoke([('human', 'Hi, what time is it?')])\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: \n",
      "Tool Calls: [{'name': 'Time', 'args': {}, 'id': 'call_MkJuaQWp8emHHhj0RGBikfxc', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([('human', 'Hi, what time is it?')])\n",
    "\n",
    "print(f\"Content: {response.content}\")\n",
    "print(f\"Tool Calls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there's now no text content, but there is a tool call! It wants us to call the Tavily Search tool.\n",
    "\n",
    "This isn't calling that tool yet - it's just telling us to. In order to actually call it, we'll want to create our agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(model, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, what time is it?', id='739397a1-1084-437a-950f-9696436cca48'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_OGVhCP4A2VhNJwhBZ3uY6udI', 'function': {'arguments': '{}', 'name': 'Time'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 56, 'total_tokens': 65}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3f177e86-24a9-4318-8139-fa4a7a927e3c-0', tool_calls=[{'name': 'Time', 'args': {}, 'id': 'call_OGVhCP4A2VhNJwhBZ3uY6udI', 'type': 'tool_call'}], usage_metadata={'input_tokens': 56, 'output_tokens': 9, 'total_tokens': 65}),\n",
       " ToolMessage(content='09:32:09 PM', name='Time', id='fd9b1553-1bad-48c5-ab9e-99bd236104cb', tool_call_id='call_OGVhCP4A2VhNJwhBZ3uY6udI'),\n",
       " AIMessage(content='It is currently 09:32:09 PM.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 78, 'total_tokens': 90}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7a2923a9-c9f1-4936-98bf-7ee07d7f7b27-0', usage_metadata={'input_tokens': 78, 'output_tokens': 12, 'total_tokens': 90})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"messages\": [('human', 'Hi, what time is it?')]})\n",
    "\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YWeT7kEf3dTzWCr68gD45tZk', 'function': {'arguments': '{}', 'name': 'Time'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 55, 'total_tokens': 64}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e4cc0e64-9f25-484a-991f-d6fe1b86beb6-0', tool_calls=[{'name': 'Time', 'args': {}, 'id': 'call_YWeT7kEf3dTzWCr68gD45tZk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 55, 'output_tokens': 9, 'total_tokens': 64})]}}\n",
      "---\n",
      "{'tools': {'messages': [ToolMessage(content='09:26:03 PM', name='Time', tool_call_id='call_YWeT7kEf3dTzWCr68gD45tZk')]}}\n",
      "---\n",
      "{'agent': {'messages': [AIMessage(content='The current time is 09:26:03 PM.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 77, 'total_tokens': 90}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2d9d90bd-0ac6-4fbb-8eae-5752badddaef-0', usage_metadata={'input_tokens': 77, 'output_tokens': 13, 'total_tokens': 90})]}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [(\"human\", \"whats time is it?\")]}\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful Agent\n",
    "\n",
    "As mentioned earlier, this agent is stateless. This means it does not remember previous interactions. To give it memory we need to pass in a checkpointer. When passing in a checkpointer, we also have to pass in a thread_id when invoking the agent (so it knows which thread/conversation to resume from).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_memory = create_react_agent(model, tools, checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"0\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, what time is it?', id='0005a66d-b662-46c7-bff5-6200a8583d0b'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_uEs68gOvLK3kO3XDaeAoSMp6', 'function': {'arguments': '{}', 'name': 'Time'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 56, 'total_tokens': 65}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-43d6444a-6dd7-4d77-ac4b-caf769e9cfd8-0', tool_calls=[{'name': 'Time', 'args': {}, 'id': 'call_uEs68gOvLK3kO3XDaeAoSMp6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 56, 'output_tokens': 9, 'total_tokens': 65}),\n",
       " ToolMessage(content='09:35:22 PM', name='Time', id='3cb0d90a-1566-4e73-af4b-3e6f121ba629', tool_call_id='call_uEs68gOvLK3kO3XDaeAoSMp6'),\n",
       " AIMessage(content='The current time is 09:35:22 PM.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 78, 'total_tokens': 91}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f8834cd2-25e3-4d57-b31f-00fa69905d32-0', usage_metadata={'input_tokens': 78, 'output_tokens': 13, 'total_tokens': 91})]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_with_memory.invoke(\n",
    "    {\"messages\": [('human', 'Hi, what time is it?')]}, config\n",
    ")\n",
    "\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we pass the same `thread_id`, the conversation context is retained via the saved state (i.e. stored list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi, what time is it?', id='0005a66d-b662-46c7-bff5-6200a8583d0b'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_uEs68gOvLK3kO3XDaeAoSMp6', 'function': {'arguments': '{}', 'name': 'Time'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 56, 'total_tokens': 65}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-43d6444a-6dd7-4d77-ac4b-caf769e9cfd8-0', tool_calls=[{'name': 'Time', 'args': {}, 'id': 'call_uEs68gOvLK3kO3XDaeAoSMp6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 56, 'output_tokens': 9, 'total_tokens': 65}),\n",
       "  ToolMessage(content='09:35:22 PM', name='Time', id='3cb0d90a-1566-4e73-af4b-3e6f121ba629', tool_call_id='call_uEs68gOvLK3kO3XDaeAoSMp6'),\n",
       "  AIMessage(content='The current time is 09:35:22 PM.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 78, 'total_tokens': 91}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f8834cd2-25e3-4d57-b31f-00fa69905d32-0', usage_metadata={'input_tokens': 78, 'output_tokens': 13, 'total_tokens': 91}),\n",
       "  HumanMessage(content='What is 2 hours after time you have told before?', id='2b656f8b-6fc6-467b-b4df-e052af4158db'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ib1xhvgiFXSOM794Bq1vQw6t', 'function': {'arguments': '{\"args\":[\"2 hours after 09:35:22 PM\"]}', 'name': 'Time'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 110, 'total_tokens': 132}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e71918d9-975b-4a3d-afe0-059f5ec26648-0', tool_calls=[{'name': 'Time', 'args': {'args': ['2 hours after 09:35:22 PM']}, 'id': 'call_ib1xhvgiFXSOM794Bq1vQw6t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 110, 'output_tokens': 22, 'total_tokens': 132}),\n",
       "  ToolMessage(content='09:35:30 PM', name='Time', id='e9ac0c3f-e783-4833-8299-8f00608483a1', tool_call_id='call_ib1xhvgiFXSOM794Bq1vQw6t'),\n",
       "  AIMessage(content='2 hours after 09:35:22 PM is 11:35:22 PM.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 145, 'total_tokens': 165}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2bd26cab-6ef7-41a0-af34-83b48fd076d8-0', usage_metadata={'input_tokens': 145, 'output_tokens': 20, 'total_tokens': 165})]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_memory.invoke(\n",
    "    {\"messages\": [('human', 'What is 2 hours after time you have told before?')]}, config\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
