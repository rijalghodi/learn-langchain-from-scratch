{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Create Tools\n",
    "\n",
    "Tools is something that agent can use. For example function to browser, database query, or time getter. \n",
    "\n",
    "References: [How to Custom Tools](https://python.langchain.com/v0.2/docs/how_to/custom_tools/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is common way to build tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, what is 2 + 2?', id='e3a55843-eaa2-4e50-b3e3-390786c7b64d'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_yjebeuTYiZAmwDFUZWzqXc7j', 'function': {'arguments': '{\"a\":2,\"b\":2}', 'name': 'Add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 57, 'total_tokens': 74}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ebf39cbc-dc29-451d-b44f-259129a0d96a-0', tool_calls=[{'name': 'Add', 'args': {'a': 2, 'b': 2}, 'id': 'call_yjebeuTYiZAmwDFUZWzqXc7j', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 17, 'total_tokens': 74}),\n",
       " ToolMessage(content='4', name='Add', id='3a06a03a-3ad6-4853-bb04-a518b7b0734d', tool_call_id='call_yjebeuTYiZAmwDFUZWzqXc7j'),\n",
       " AIMessage(content='2 + 2 is equal to 4.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 82, 'total_tokens': 93}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c290e96e-f306-49d1-b66b-beccc23b57a9-0', usage_metadata={'input_tokens': 82, 'output_tokens': 11, 'total_tokens': 93})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Create a function\n",
    "def add(a: int, b: int):\n",
    "    return a + b\n",
    "\n",
    "# Create a tool\n",
    "add_tool = StructuredTool.from_function(\n",
    "    name=\"Add\", \n",
    "    func=add,  \n",
    "    description=\"Useful for adding two numbers\",\n",
    ")\n",
    "\n",
    "tools = [add_tool]\n",
    "\n",
    "# Describe model\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Create agent from tools and model\n",
    "agent_executor = create_react_agent(model, tools)\n",
    "\n",
    "response = agent_executor.invoke({\"messages\": [('human', 'Hi, what is 2 + 2?')]})\n",
    "\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build tools, we need specify:\n",
    "\n",
    "| **Name**        | **Type**              | **Description**                                                                                                                                           |\n",
    "|-----------------|-----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| `name`          | `str`                 | Must be unique within a set of tools provided to an LLM or agent.                                                                                         |\n",
    "| `description`   | `str`                 | Describes what the tool does. Used as context by the LLM or agent.                                                                                         |\n",
    "| `args_schema`   | `Pydantic BaseModel`  | Optional but recommended, can be used to provide more information (e.g., few-shot examples) or validation for expected parameters.                         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langchain has three ways to create a tool:\n",
    "\n",
    "[1. Tool from functions](#1)\n",
    "[2. Tool from LangChain Runnables](#2)\n",
    "[3. Tool By sub-classing from BaseTool](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Create Tool from Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Using `StructuredTool.from_function` Class\n",
    "\n",
    "- This is most strightforward and flexible way to create a tool.\n",
    "- Here, we can specify the sync and async function and args scheme\n",
    "\n",
    "Reference: [`StructuredTool`](https://api.python.langchain.com/en/latest/tools/langchain_core.tools.StructuredTool.html#langchain_core.tools.StructuredTool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Specify arg scheme\n",
    "class CalculatorArgsScheme(BaseModel):\n",
    "    a: int = Field(description=\"first number\")\n",
    "    b: int = Field(description=\"second number\")\n",
    "\n",
    "# Define sync and async functions\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers sync.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "async def amultiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers async.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "# We can define syn and async functions using StructuredTool\n",
    "calculator = StructuredTool.from_function(func=multiply, \n",
    "                                          coroutine=amultiply, \n",
    "                                          args_schema=CalculatorArgsScheme,\n",
    "                                          description=\"Multiply two numbers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiply two numbers\n",
      "6\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': 'CalculatorArgsScheme',\n",
       " 'type': 'object',\n",
       " 'properties': {'a': {'title': 'A',\n",
       "   'description': 'first number',\n",
       "   'type': 'integer'},\n",
       "  'b': {'title': 'B', 'description': 'second number', 'type': 'integer'}},\n",
       " 'required': ['a', 'b']}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(calculator.description)\n",
    "print(calculator.invoke({\"a\": 2, \"b\": 3}))\n",
    "print(await calculator.ainvoke({\"a\": 2, \"b\": 5}))\n",
    "calculator.args_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Using `@tool` decorator\n",
    "\n",
    "- This is more simple way, yet more limited\n",
    "\n",
    "References: [@tool](https://api.python.langchain.com/en/latest/tools/langchain_core.tools.tool.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect some of the attributes associated with the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.tools.StructuredTool'>\n",
      "multiply\n",
      "Multiply two numbers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': 'multiplySchema',\n",
       " 'description': 'Multiply two numbers.',\n",
       " 'type': 'object',\n",
       " 'properties': {'a': {'title': 'A', 'type': 'integer'},\n",
       "  'b': {'title': 'B', 'type': 'integer'}},\n",
       " 'required': ['a', 'b']}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @tool decorator will produce StructuredTool object\n",
    "print(type(multiply))\n",
    "\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "multiply.args_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, langchain will create async function from the function. But we cant modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await multiply.ainvoke({\"a\": 22, \"b\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To specify args scheme, there is two ways: First, using annotated class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'multiply_by_maxSchema',\n",
       " 'description': 'Multiply a by the maximum of b.',\n",
       " 'type': 'object',\n",
       " 'properties': {'a': {'title': 'A',\n",
       "   'description': 'scale factor',\n",
       "   'type': 'string'},\n",
       "  'b': {'title': 'B',\n",
       "   'description': 'list of ints over which to take maximum',\n",
       "   'type': 'array',\n",
       "   'items': {'type': 'integer'}}},\n",
       " 'required': ['a', 'b']}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated, List\n",
    "\n",
    "@tool\n",
    "def multiply_by_max(\n",
    "    a: Annotated[str, \"scale factor\"],\n",
    "    b: Annotated[List[int], \"list of ints over which to take maximum\"],\n",
    ") -> int:\n",
    "    \"\"\"Multiply a by the maximum of b.\"\"\"\n",
    "    return a * max(b)\n",
    "\n",
    "multiply_by_max.args_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, using `parse_docstring=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'fooSchema',\n",
       " 'description': 'The foo.',\n",
       " 'type': 'object',\n",
       " 'properties': {'bar': {'title': 'Bar',\n",
       "   'description': 'The bar.',\n",
       "   'type': 'string'},\n",
       "  'baz': {'title': 'Baz', 'description': 'The baz.', 'type': 'integer'}},\n",
       " 'required': ['bar', 'baz']}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tool(parse_docstring=True)\n",
    "def foo(bar: str, baz: int) -> str:\n",
    "    \"\"\"The foo.\n",
    "\n",
    "    Args:\n",
    "        bar: The bar.\n",
    "        baz: The baz.\n",
    "    \"\"\"\n",
    "    return bar\n",
    "\n",
    "foo.args_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tools From Runnable <div id=\"2\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Document\\Machine_Learning_Journey\\Projects\\Langchain\\learn-langchain-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\_api\\beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer_style': {'title': 'Answer Style', 'type': 'string'}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.language_models import GenericFakeChatModel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"human\", \"Hello. Please respond in the style of {answer_style}.\")]\n",
    ")\n",
    "\n",
    "# Placeholder LLM\n",
    "llm = GenericFakeChatModel(messages=iter([\"hello matey\"]))\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "as_tool = chain.as_tool(\n",
    "    name=\"Style responder\", description=\"Description of when to use tool.\"\n",
    ")\n",
    "as_tool.args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-Class BaseModel <div id=\"2\"></div>\n",
    "\n",
    "- This is the most flexible method, it provides the largest degree of control, at the expense of more effort and code.\n",
    "- Basically, all tools must be implemented `BaseModel` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Type\n",
    "\n",
    "from langchain.pydantic_v1 import BaseModel\n",
    "from langchain_core.callbacks import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "\n",
    "class CalculatorInput(BaseModel):\n",
    "    a: int = Field(description=\"first number\")\n",
    "    b: int = Field(description=\"second number\")\n",
    "\n",
    "\n",
    "class CustomCalculatorTool(BaseTool):\n",
    "    name = \"Calculator\"\n",
    "    description = \"useful for when you need to answer questions about math\"\n",
    "    args_schema: Type[BaseModel] = CalculatorInput\n",
    "    return_direct: bool = True\n",
    "\n",
    "    def _run(\n",
    "        self, a: int, b: int, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        return a * b\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        a: int,\n",
    "        b: int,\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        # If the calculation is cheap, you can just delegate to the sync implementation\n",
    "        # as shown below.\n",
    "        # If the sync calculation is expensive, you should delete the entire _arun method.\n",
    "        # LangChain will automatically provide a better implementation that will\n",
    "        # kick off the task in a thread to make sure it doesn't block other async code.\n",
    "        return self._run(a, b, run_manager=run_manager.get_sync())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
